{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript\n",
        "\n",
        "def prevent_disconnect():\n",
        "    js_code = \"\"\"\n",
        "    function ClickConnect(){\n",
        "        console.log(\"Working\");\n",
        "        document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "    }\n",
        "    setInterval(ClickConnect,60000)\n",
        "    \"\"\"\n",
        "    display(Javascript(js_code))\n",
        "\n",
        "prevent_disconnect()"
      ],
      "metadata": {
        "id": "lktFH-UEnmZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFQUEWFEu-bD"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit\n",
        "!pip install pyngrok\n",
        "!pip install ultralytics==8.0.196\n",
        "!pip install ffmpeg-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# GitHub personal access token\n",
        "github_token = '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'\n",
        "\n",
        "def download_model_via_api(url, save_path, token):\n",
        "    headers = {'Authorization': f'token {token}', 'Accept': 'application/vnd.github.v3.raw'}\n",
        "    response = requests.get(url, headers=headers)\n",
        "    if response.status_code == 200:\n",
        "        with open(save_path, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "    else:\n",
        "        print(f\"Failed to download model. Status code: {response.status_code}, Response: {response.text}\")\n",
        "        raise Exception(\"Failed to download model weights.\")\n",
        "\n",
        "# Adjusted for GitHub API\n",
        "model_weights_url = 'https://api.github.com/repos/leekaize/COS30018/contents/01_MultiClassModelTraining/AdamW%20Optimizer/yolov8s.pt/100epochs/YoloMultiClass100epochs%20(AdamW%20-%20lr_%200.001)%20v8s/weights/best.pt?ref=main'\n",
        "model_weights_path = '/content/model-weights.pt'\n",
        "\n",
        "# Make sure the save path and token are correctly defined\n",
        "download_model_via_api(model_weights_url, model_weights_path, github_token)"
      ],
      "metadata": {
        "id": "Im3jqysKg7vQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f11AGJa1waxE"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "import ultralytics\n",
        "import streamlit as st\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image, ImageOps\n",
        "import cv2\n",
        "import tempfile\n",
        "import numpy as np\n",
        "import os\n",
        "import ffmpeg\n",
        "\n",
        "# Load the YOLO model\n",
        "model = YOLO('/content/model-weights.pt')\n",
        "\n",
        "def detection_page():\n",
        "    st.title(\"Detection\")\n",
        "    # Create two columns for the layout\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    with col1:\n",
        "        # File uploader allows user to add their own image or video\n",
        "        uploaded_file = st.file_uploader(\"Upload an image or video...\", type=[\"png\", \"jpg\", \"jpeg\", \"mp4\"])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        file_type = uploaded_file.type.split('/')[0]\n",
        "        if file_type == 'image':\n",
        "            with col2:\n",
        "                image = Image.open(uploaded_file).convert('RGB')\n",
        "                image = ImageOps.exif_transpose(image)  # Automatically adjust the orientation based on EXIF\n",
        "                results = model.predict(image, conf=0.5)\n",
        "                np_array = results[0].plot()\n",
        "                np_array = cv2.cvtColor(np_array, cv2.COLOR_BGR2RGB)  # Correct color inversion\n",
        "                predicted_image = Image.fromarray(np_array, 'RGB')\n",
        "                st.image(predicted_image, caption='Processed Image with Detections.', use_column_width=True)\n",
        "        elif file_type == 'video':\n",
        "            with col2:\n",
        "                tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')\n",
        "                tfile.write(uploaded_file.read())\n",
        "                # Predict directly on the video file\n",
        "                results = model.predict(tfile.name, save=True, project=\"videos\")\n",
        "                processed_video_path = results[0].save_dir + results[0].path\n",
        "                processed_video_path = processed_video_path.replace(\"/tmp/\", \"/\")\n",
        "                temp_video_path = processed_video_path.replace(\".mp4\", \".avi\")\n",
        "\n",
        "                (\n",
        "                    ffmpeg\n",
        "                    .input(temp_video_path)\n",
        "                    .output(processed_video_path, vcodec='libx264', crf=28, preset='ultrafast', movflags='faststart', acodec='aac', strict='experimental')\n",
        "                    .run()\n",
        "                )\n",
        "\n",
        "                st.video(processed_video_path)\n",
        "\n",
        "def planogram_page():\n",
        "    st.title(\"Planogram Compliance\")\n",
        "    st.write(\"Planogram compliance functionality will be implemented here.\")\n",
        "\n",
        "def contribute_page():\n",
        "    st.title(\"Contribute\")\n",
        "    st.write(\"Contribute to incremental learning model by providing feedback.\")\n",
        "\n",
        "def main():\n",
        "    st.set_page_config(page_title=\"AI Retail Vision\", layout=\"wide\")\n",
        "\n",
        "    # Using radio buttons for navigation\n",
        "    tab_names = [\"Detection\", \"Planogram\", \"Contribute\"]\n",
        "    selected_tab = st.sidebar.radio(\"Navigation\", tab_names)\n",
        "\n",
        "    if selected_tab == \"Detection\":\n",
        "        detection_page()\n",
        "    elif selected_tab == \"Planogram\":\n",
        "        planogram_page()\n",
        "    elif selected_tab == \"Contribute\":\n",
        "        contribute_page()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1h72tihRyK-3"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "# Kill previous ngrok instances\n",
        "ngrok.kill()\n",
        "ngrok.set_auth_token('2g80v7Wvh6Wrlh2yFO25i3BUpy0_37mg8RF51YAddgyXE3eag')\n",
        "\n",
        "# Start the Streamlit app in the background\n",
        "get_ipython().system_raw('streamlit run --server.port 8501 app.py &')\n",
        "\n",
        "# Set up the ngrok tunnel to the streamlit port 8501\n",
        "public_url = ngrok.connect(addr=\"8501\", proto='http', bind_tls=True)\n",
        "print(\"Streamlit is running at \", public_url)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}