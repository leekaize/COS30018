{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "PFQUEWFEu-bD"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit\n",
        "!pip install pyngrok\n",
        "!pip install ultralytics==8.0.196\n",
        "!pip install ffmpeg-python\n",
        "!pip install roboflow\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# GitHub personal access token\n",
        "github_token = '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'\n",
        "\n",
        "def download_model_via_api(url, save_path, token):\n",
        "    headers = {'Authorization': f'token {token}', 'Accept': 'application/vnd.github.v3.raw'}\n",
        "    response = requests.get(url, headers=headers)\n",
        "    if response.status_code == 200:\n",
        "        with open(save_path, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "    else:\n",
        "        print(f\"Failed to download model. Status code: {response.status_code}, Response: {response.text}\")\n",
        "        raise Exception(\"Failed to download model weights.\")\n",
        "\n",
        "# Adjusted for GitHub API\n",
        "model_weights_url = 'https://api.github.com/repos/leekaize/COS30018/contents/01_MultiClassModelTraining/SGD%20Optimizer/yolov8s.pt/150epochs/YoloMultiClass150epochs%20%20(SGD%20-%20lr_%200.01)%20v8s/train3/weights/best.pt?ref=main'\n",
        "model_weights_path = '/content/model-weights.pt'\n",
        "\n",
        "# Make sure the save path and token are correctly defined\n",
        "download_model_via_api(model_weights_url, model_weights_path, github_token)"
      ],
      "metadata": {
        "id": "Im3jqysKg7vQ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f11AGJa1waxE",
        "outputId": "e32ce817-deb4-4158-cfa2-53e011d98867"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import ultralytics\n",
        "import streamlit as st\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image, ImageOps\n",
        "import cv2\n",
        "import tempfile\n",
        "import numpy as np\n",
        "import os\n",
        "import ffmpeg\n",
        "from roboflow import Roboflow\n",
        "\n",
        "# Load the YOLO model\n",
        "model = YOLO('/content/model-weights.pt')\n",
        "\n",
        "rf = Roboflow(api_key=\"Qcpny2sVf8g33aLNl9iL\")\n",
        "project = rf.workspace(\"cos30018\").project(\"incrementallearning\")\n",
        "\n",
        "def upload_to_roboflow(image_path, annotation_path, project):\n",
        "    try:\n",
        "        response = project.upload(image_path=image_path, annotation_path=annotation_path, annotation_format=\"yolo\")\n",
        "        print(f\"Uploaded {image_path} and {annotation_path} successfully.\")\n",
        "        print(\"Upload response:\", response)\n",
        "        # Delete files after successful upload\n",
        "        os.remove(image_path)\n",
        "        os.remove(annotation_path)\n",
        "        print(f\"Deleted {image_path} and {annotation_path} after upload.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to upload {image_path} and {annotation_path}: {e}\")\n",
        "\n",
        "def detection_page():\n",
        "    st.title(\"Detection\")\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    with col1:\n",
        "        uploaded_file = st.file_uploader(\"Upload an image or video...\", type=[\"png\", \"jpg\", \"jpeg\", \"mp4\"])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        # Reset session state for valid_detections on new file upload\n",
        "        st.session_state.valid_detections = []\n",
        "\n",
        "        file_type = uploaded_file.type.split('/')[0]\n",
        "        if file_type == 'image':\n",
        "            with col2:\n",
        "                image = Image.open(uploaded_file).convert('RGB')\n",
        "                image = ImageOps.exif_transpose(image)\n",
        "                results = model.predict(image, conf=0.5)\n",
        "                np_array = results[0].plot()\n",
        "                np_array = cv2.cvtColor(np_array, cv2.COLOR_BGR2RGB)\n",
        "                predicted_image = Image.fromarray(np_array, 'RGB')\n",
        "                st.image(predicted_image, caption='Processed Image with Detections.', use_column_width=True)\n",
        "        elif file_type == 'video':\n",
        "            with col2:\n",
        "                tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')\n",
        "                tfile.write(uploaded_file.read())\n",
        "                results = model.predict(tfile.name, save=True, project=\"videos\")\n",
        "                processed_video_path = results[0].save_dir + results[0].path\n",
        "                processed_video_path = processed_video_path.replace(\"/tmp/\", \"/\")\n",
        "                temp_video_path = processed_video_path.replace(\".mp4\", \".avi\")\n",
        "\n",
        "                (\n",
        "                    ffmpeg\n",
        "                    .input(temp_video_path)\n",
        "                    .output(processed_video_path, vcodec='libx264', crf=28, preset='ultrafast', movflags='faststart', acodec='aac', strict='experimental')\n",
        "                    .run()\n",
        "                )\n",
        "\n",
        "                st.video(processed_video_path)\n",
        "\n",
        "def planogram_page():\n",
        "    st.title(\"Planogram Compliance\")\n",
        "    st.write(\"Planogram compliance functionality will be implemented here.\")\n",
        "\n",
        "def contribute_page():\n",
        "    st.title(\"Contribute\")\n",
        "    st.write(\"Contribute to incremental learning model by providing feedback.\")\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    if 'valid_detections' not in st.session_state:\n",
        "        st.session_state.valid_detections = []\n",
        "\n",
        "    with col1:\n",
        "        uploaded_file = st.file_uploader(\"Upload an image\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        # Reset session state for valid_detections and radio buttons on new file upload\n",
        "        st.session_state.valid_detections = []\n",
        "        for key in list(st.session_state.keys()):\n",
        "            if key.startswith(\"radio_\"):\n",
        "                del st.session_state[key]\n",
        "\n",
        "        image = Image.open(uploaded_file).convert('RGB')\n",
        "        image = ImageOps.exif_transpose(image)\n",
        "        results = model.predict(image, conf=0.3)\n",
        "        detections = results[0].boxes  # Detected bounding boxes\n",
        "\n",
        "        # Show the full image with detections in the first column\n",
        "        np_array = results[0].plot()\n",
        "        np_array = cv2.cvtColor(np_array, cv2.COLOR_BGR2RGB)\n",
        "        predicted_image = Image.fromarray(np_array, 'RGB')\n",
        "        with col1:\n",
        "            st.image(predicted_image, caption='Processed Image with Detections.', use_column_width=True)\n",
        "\n",
        "        if detections is not None and len(detections) > 0:\n",
        "            with col2:\n",
        "              with st.form(key='detections_form'):\n",
        "                  for i, box in enumerate(detections):\n",
        "                      bbox = box.xyxy[0].cpu().numpy().tolist()  # Convert tensor to list\n",
        "                      x1, y1, x2, y2 = map(int, bbox)\n",
        "                      margin = 50  # Margin to make the cropped image slightly larger\n",
        "                      x1, y1 = max(0, x1 - margin), max(0, y1 - margin)\n",
        "                      x2, y2 = min(image.width, x2 + margin), min(image.height, y2 + margin)\n",
        "                      cropped_image = image.crop((x1, y1, x2, y2))\n",
        "\n",
        "                      label = int(box.cls.cpu().item())  # Get the class label\n",
        "                      label_name = \"Imprecise\" if label == 0 else \"Missing\"  # Adjust based on your class labels\n",
        "\n",
        "                      col_image, col_radio = st.columns([1, 2])\n",
        "                      with col_image:\n",
        "                          st.image(cropped_image, caption=f\"Detection {i+1}\", width=150)\n",
        "                      with col_radio:\n",
        "                          st.radio(f\"[{label_name}] Is detection {i+1} correct?\", ('Yes', 'No'), key=f\"radio_{i}\", index=0)\n",
        "\n",
        "                  submit_button = st.form_submit_button(label='Finish')\n",
        "                  if submit_button:\n",
        "                      # After all detections are rated\n",
        "                      annotations = []\n",
        "                      for i, box in enumerate(detections):\n",
        "                          if st.session_state[f\"radio_{i}\"] == 'Yes':\n",
        "                              bbox = box.xyxy[0].cpu().numpy().tolist()\n",
        "                              x1, y1, x2, y2 = map(int, bbox)\n",
        "                              label = int(box.cls.cpu().item())\n",
        "                              x_center = (x1 + x2) / 2 / image.width\n",
        "                              y_center = (y1 + y2) / 2 / image.height\n",
        "                              width = (x2 - x1) / image.width\n",
        "                              height = (y2 - y1) / image.height\n",
        "                              annotations.append(f\"{label} {x_center} {y_center} {width} {height}\")\n",
        "\n",
        "                      # Save the annotated image\n",
        "                      annotated_image_path = os.path.splitext(uploaded_file.name)[0] + \"_annotated.jpg\"\n",
        "                      annotations_path = os.path.splitext(uploaded_file.name)[0] + \".txt\"\n",
        "                      image.save(annotated_image_path)\n",
        "\n",
        "                      with open(annotations_path, 'w') as f:\n",
        "                          f.write(\"\\n\".join(annotations))\n",
        "\n",
        "                      # Upload to Roboflow\n",
        "                      upload_to_roboflow(annotated_image_path, annotations_path, project)\n",
        "\n",
        "                      st.success(\"All detections have been rated and uploaded to Roboflow.\")\n",
        "                      # Reset session state\n",
        "                      st.session_state.valid_detections = []\n",
        "\n",
        "def main():\n",
        "    st.set_page_config(page_title=\"AI Retail Vision\", layout=\"wide\")\n",
        "\n",
        "    tab_names = [\"Detection\", \"Planogram\", \"Contribute\"]\n",
        "    selected_tab = st.sidebar.radio(\"Navigation\", tab_names)\n",
        "\n",
        "    if selected_tab == \"Detection\":\n",
        "        detection_page()\n",
        "    elif selected_tab == \"Planogram\":\n",
        "        planogram_page()\n",
        "    elif selected_tab == \"Contribute\":\n",
        "        contribute_page()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "1h72tihRyK-3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cce024d4-41f4-4966-f202-2023064b01f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit is running at  NgrokTunnel: \"https://9418-34-80-192-243.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "# Kill previous ngrok instances\n",
        "ngrok.kill()\n",
        "ngrok.set_auth_token('2g80v7Wvh6Wrlh2yFO25i3BUpy0_37mg8RF51YAddgyXE3eag')\n",
        "\n",
        "# Start the Streamlit app in the background\n",
        "get_ipython().system_raw('streamlit run --server.port 8501 app.py &')\n",
        "\n",
        "# Set up the ngrok tunnel to the streamlit port 8501\n",
        "public_url = ngrok.connect(addr=\"8501\", proto='http', bind_tls=True)\n",
        "print(\"Streamlit is running at \", public_url)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}